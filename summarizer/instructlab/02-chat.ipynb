{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603889ff-e355-4c9e-929a-45e8150aa0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61faf199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b694cfeb-1653-4555-84ce-875b3885150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(\n",
    "            \">>>{}: The output is: {}. \\n\\nThe metadata is {} \\n\\n\".format(\n",
    "                i + 1,\n",
    "                (\n",
    "                    doc.page_content[:100] + \"...\"\n",
    "                    if len(doc.page_content) > 100\n",
    "                    else doc.page_content\n",
    "                ),\n",
    "                doc.metadata,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0788aef1-0fe8-4205-ba3d-741bb5cf392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "db = FAISS.load_local(\n",
    "    \"summarizer_index\", embeddings_model, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94184d22-46ad-45e7-8a00-38c298b7e607",
   "metadata": {},
   "source": [
    "## Perform semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82dd70e3-e3ca-4b2d-a238-3ed466e41618",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "worked with partners\n",
    "\"\"\"\n",
    "docs = db.similarity_search(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff62b2cc-cebc-43ab-a2ff-d785f40ca73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>1: The output is: have just been hired\", has no right to judge your work. Good luck to those who\n",
      "still have to do with.... \n",
      "\n",
      "The metadata is {'source': '../../docs/Profile.pdf', 'page': 1} \n",
      "\n",
      "\n",
      ">>>2: The output is: Technical Debates, Supporting Customer Cases and Troubleshooting and\n",
      "much more, for Cisco EPN Manage.... \n",
      "\n",
      "The metadata is {'source': '../../docs/Profile.pdf', 'page': 2} \n",
      "\n",
      "\n",
      ">>>3: The output is: June 2021 - July 2022 (1 year 2 months)\n",
      "Remote\n",
      "Is this the beginning of a great adventure?\n",
      "Nokia\n",
      "Opt.... \n",
      "\n",
      "The metadata is {'source': '../../docs/Profile.pdf', 'page': 1} \n",
      "\n",
      "\n",
      ">>>4: The output is: My Individual Goals\n",
      " 02:36 PM\n",
      "11/18/2024\n",
      "Page 2 of 4\n",
      "Goal Section \n",
      "Group Goal Add goal progress or d.... \n",
      "\n",
      "The metadata is {'source': '../../docs/My_Individual_Goals.pdf', 'page': 1} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_output(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b513bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e071684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ibm-granite/granite-3.0-2b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66072554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU device with no GPU\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# device_id = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a8f29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1fd58367474b82b1e0980157b50ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Metal Performance Shaders (MPS) for Apple GPUs\n",
    "device_id = \"mps\"\n",
    "device = torch.device(device_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edc12b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device_id,\n",
    "    temperature=0.2,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1000,  # important to avoid generation errors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6f69b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmartino/projects/AI/learning/chat-with-your-data-using-chatgpt-3806110/venv/lib/python3.11/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             \"\"\"You are an assistant for question-answering tasks. \n",
    "# Use the following pieces of retrieved context to answer the question. \n",
    "# If you don't know the answer, just say that you don't know. \n",
    "# Use four sentences maximum and keep the answer concise.\n",
    "# Question: {question} \n",
    "# Context: {context} \n",
    "# Answer: <your answer here>\n",
    "# Word count: <total word count>\n",
    "# \"\"\",\n",
    "#         )\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb9901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8fbec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=pipeline)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# combine multiple steps in a single chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()  # convert the chat message to a string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57b73dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "You are the person for which we provide the development and individual item reports\n",
    "and the LinkedIn profile description.\n",
    "Generate a profile description for yourself.\n",
    "The profile must include:\n",
    "- one paragraph with the description of professional role, highlighting the competences\n",
    "- one paragraph with a comma separated list of recent achievements\n",
    "- one paragraph with a comma separated list of skills\n",
    "\n",
    "Use first person as \"I am\" instead of \"He is\".\n",
    "Use generic terms instead of specific examples: \"DevOps\" instead of \"Jenkins\".\n",
    "Avoid to mention customer names like Temenos.\n",
    "Use skills categorizies when possible.\n",
    "At the end of each sentence add a list of the reference source files.\n",
    "At the end of the response, include a count of words.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1ab3171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I am Daniele Martinoli, a Principal Software Engineer at Red Hat with over 20 years of experience in software development. I specialize in software architecture, design, and development, with a focus on TDD, MDD, Java, Spring, Hibernate, REST, and Agile (Scrum). I have extensive experience working with Red Hat products and technologies, including OpenShift Container Platform and Red Hat learning day programs.\n",
      "\n",
      "Recent Achievements:\n",
      "\n",
      "* Successfully drove the development of software solutions for customers in the Service Provider and Enterprise markets.\n",
      "* Prepared and taught a lesson on \"cloud native development\" to students of the last year of computer programming.\n",
      "* Completed C. Wright learning on AI programming with Python and started Feast related trainings.\n",
      "\n",
      "Skills:\n",
      "\n",
      "* Relates To: DevOps, GitOps, Blogging, English\n",
      "* Continuous Learning (Competency): Execution, Problem Solving\n",
      "* Portfolio Excellence (Competency): Red Hat Product Portfolio\n",
      "\n",
      "Development Items:\n",
      "\n",
      "* Understand and Experience the Red Hat Development Life Cycle\n",
      "* Effective communication\n",
      "* Learning AI\n",
      "* Expand Cloud architecture knowledge (get familiar with public Cloud services)\n",
      "* Learn about the Red Hat product portfolio\n",
      "* Red Hat Organization and dynamics\n",
      "\n",
      "Individual Goals:\n",
      "\n",
      "* Support Temenos Engineering in building a CI/CD pipeline for their products.\n",
      "* Evolve Customer Success via hybrid cloud experiences (Archived)\n",
      "\n",
      "In Progress Development Items:\n",
      "\n",
      "* RH Global activities (LinkUp program and Red Hat learning day)\n",
      "\n",
      "References:\n",
      "\n",
      "* LinkedIn Learning videos and courses\n",
      "* Red Hat learning day programs\n",
      "* Red Hat documentation and resources\n",
      "\n",
      "Note: Some references are not available or not applicable to this profile."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\n",
    "    question\n",
    "):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac5cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf18f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
